package io.github.exploiting.flinks.stateful.operators.advanced_fc

import java.util.UUID

import io.github.exploiting.flinks.stateful.operators.magic.ConvertHelper
import io.github.exploiting.flinks.stateful.operators.magic.Mappable._
import io.github.exploiting.flinks.stateful.operators.model._
import io.github.exploiting.flinks.stateful.operators.{SimpleTransactionSource, ThrottlingSource}
import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.scala._
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows
import org.apache.flink.streaming.api.windowing.time.Time
import org.apache.flink.util.Collector

import scala.collection.immutable

object AdvancedStatefulFlyingCarpetJob {
  // The source, at a rate of 10 elements/sec.
  val simpleTransactionSource = new ThrottlingSource[SimpleTransaction](new SimpleTransactionSource, 10)

  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime)

    val inputStream: DataStream[SimpleTransaction] = env.addSource(simpleTransactionSource)
    val result: DataStream[ScoringResult] = createJob(inputStream)

    result.print()

    println(env.getExecutionPlan)

    // execute program
    env.execute("Flink Advanced-keyed Fraudulent Transaction")
  }

  // Convert back to case class.
  def to[A]: ConvertHelper[A] = new ConvertHelper[A]

  def createJob(inputStream: DataStream[SimpleTransaction]): DataStream[ScoringResult]  = {
    // Give unique Id to incoming event for joining later in the chain.
    val uuidStream: DataStream[UuidTransaction] = inputStream.map {simpleTransaction =>
      println(s"simpleTransaction = $simpleTransaction")
        UuidTransaction(java.util.UUID.randomUUID, simpleTransaction.toMap)
    }.keyBy(inputStream => inputStream.id)

    case class DynamicKeyEvent(id: UUID, key: KeyWithValues, payload: Map[String, Any],
                               operation: (List[Key], (KeyWithValues, Value) => StateF[Double]))

    // Store the current time and location in state and retrieve the previous by this customer.
    val customKeyStream: DataStream[DynamicKeyEvent] = uuidStream
      .flatMap[DynamicKeyEvent]((ust: UuidTransaction, coll: Collector[DynamicKeyEvent]) =>
      Manager.keyedDefinitions.foreach(key =>
        coll.collect(
          DynamicKeyEvent(ust.id, List((key, ust.payload(key))), ust.payload, Manager.keyedOperations(key))
        )
      )
    )

    case class ResultEvent(id: UUID, result: Any)
    val stateStream: DataStream[ResultEvent] = customKeyStream
      .keyBy(dynamicKey => dynamicKey.key)
      .mapWithState[ResultEvent, Map[KeyWithValues, Value]] {
      case (event: DynamicKeyEvent, maybeState: Option[Map[KeyWithValues, Value]]) =>
        val ops: (KeyWithValues, Value) => StateF[Double] = event.operation._2
        // extract all needed values from the payload
        val constructedValue: Seq[Any] = event.operation._1.map(event.payload(_))

        import io.github.exploiting.flinks.stateful.operators.magic.ToTuple._
        val tup = constructedValue.toTuple

        val interpreter = FlinkInterpreter(maybeState)
        val result = ops(event.key, tup).foldMap(interpreter)

        (ResultEvent(event.id, result), Some(interpreter.state))
    }


    // Join the original event with the picked up state based on UUID.
    val enrichedStream = uuidStream.join(stateStream)
      .where(_.id)
      .equalTo(_.id)
      .window(TumblingEventTimeWindows.of(Time.milliseconds(100))) //we wait 100 millis before discarding the event).
      .apply { (simpleTransaction, resultTransaction) =>
      // TODO: currently, 2 enriched events are being produced per simple event,
      // need to group all the UuidWithState together with one UuidTransaction,
      // possibly will have to use 'fold' or collect state with custom trigger

      EnrichedSimpleTransaction(simpleTransaction.id, to[SimpleTransaction].from(simpleTransaction.payload),
        resultTransaction.result.asInstanceOf[Double],resultTransaction.result.asInstanceOf[Double])
      }

    //now we can score the improved model
    val result = enrichedStream.map(event =>
      ScoringResult(event, FraudRules.scoreFlyingCarpet(event))
    )
    result
  }
}



/**
  * History class that is a circular buffer, oldest elements are overwritten when the buffer is full.
  * @param maxSize How many items we want to store.
  * @param buffer Initialize it with a buffer.
  * @tparam A The type we store in this class.
  */
case class History[A](maxSize: Int, buffer: Vector[A] = immutable.Vector.empty[A]) {
  type CircularBuffer = immutable.Vector[A]

  private def addToCircularBuffer(item : A) : CircularBuffer  =
    if(maxSize > 0)
      buffer.drop(buffer.size - maxSize + 1) :+ item
    else
      buffer

  def :+(item: A): History[A] = History(maxSize, addToCircularBuffer(item))
}
