package io.github.exploiting.flinks.stateful.operators.advanced_fc

import io.github.exploiting.flinks.stateful.operators.magic.ConvertHelper
import io.github.exploiting.flinks.stateful.operators.magic.Mappable._
import io.github.exploiting.flinks.stateful.operators.model._
import io.github.exploiting.flinks.stateful.operators.{SimpleTransactionSource, ThrottlingSource}
import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment, _}
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows
import org.apache.flink.streaming.api.windowing.time.Time
import org.apache.flink.util.Collector

import scala.collection.immutable

object AdvancedStatefulFlyingCarpetJob {
  // The source, at a rate of 10 elements/sec.
  val simpleTransactionSource = new ThrottlingSource[SimpleTransaction](new SimpleTransactionSource, 10)

  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime)

    val inputStream: DataStream[SimpleTransaction] = env.addSource(simpleTransactionSource)
    val result = createJob(inputStream)

    result.print()

    println(env.getExecutionPlan)

    // execute program
    env.execute("Flink Advanced-keyed Fraudulent Transaction")
  }

  // Convert back to case class. 
  def to[A]: ConvertHelper[A] = new ConvertHelper[A]

  def createJob(inputStream: DataStream[SimpleTransaction]): DataStream[EnrichedTransaction]  = {
    // Give unique Id to incoming event for joining later in the chain.
    val uuidStream: DataStream[UuidTransaction] = inputStream.map {
      s => UuidTransaction(java.util.UUID.randomUUID, s.toMap)
    }.keyBy(inputStream => inputStream.id)

    val customKeyStream: DataStream[DynamicKeyEvent] = uuidStream
      .flatMap[DynamicKeyEvent]((ust: UuidTransaction, coll: Collector[DynamicKeyEvent]) =>
      Manager.keyedDefinitions.foreach(key =>
        coll.collect(DynamicKeyEvent(ust.id, List((key, ust.payload(key))), ust.payload, (Manager.keyedOperations(key))))))

    val stateStream = customKeyStream
      .keyBy(dynamicKeyEvent => dynamicKeyEvent.key)
      .mapWithState[UuidWithState, DynamicState] { //At this state, the key is already taken into account, so DynamicState is the state of the particular key
      case (event: DynamicKeyEvent, maybeState: Option[DynamicState]) =>
        val evaluateOps: List[(String, Any)] = event.operation.map(op => (op, event.payload(op)))
        val prevState = maybeState.getOrElse(DynamicState(Map.empty))
        val newState = prevState.update(evaluateOps)

        val enriched = UuidWithState(event.id, event.key, prevState.state)
        (enriched, Some(newState))
    }

    // Join the original event with the picked up state based on UUID.
    val enrichedStream = uuidStream.join(stateStream)
      .where(_.id)
      .equalTo(_.id)
      .window(TumblingEventTimeWindows.of(Time.milliseconds(100))) //we wait 100 millis before discarding the event).
      .apply { (uuidTransaction, uuidWithState) =>
      EnrichedTransaction(uuidTransaction.id, uuidTransaction.payload, uuidWithState.state)
    }

    //now we can score the improved model
    val result = enrichedStream/*.map(event =>
      ScoringResult(event, FraudRules.scoreFlyingCarpet(event))
    )*/
    result
  }
}


/**
  * History class that is a circular buffer, oldest elements are overwritten when the buffer is full.
  * @param maxSize How many items we want to store.
  * @param buffer Initialize it with a buffer.
  * @tparam A The type we store in this class.
  */
case class History[A](maxSize: Int, buffer: Vector[A] = immutable.Vector.empty[A]) {
  type CircularBuffer = immutable.Vector[A]

  private def addToCircularBuffer(item : A) : CircularBuffer  =
    if(maxSize > 0)
      buffer.drop(buffer.size - maxSize + 1) :+ item
    else
      buffer

  def :+(item: A): History[A] = History(maxSize, addToCircularBuffer(item))
}
