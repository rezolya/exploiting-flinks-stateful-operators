package io.github.exploiting.flinks.stateful.operators.advanced_fc

import io.github.exploiting.flinks.stateful.operators.magic.Mappable._
import io.github.exploiting.flinks.stateful.operators.model._
import io.github.exploiting.flinks.stateful.operators.{SimpleTransactionSource, ThrottlingSource}
import org.apache.flink.api.common.state._
import org.apache.flink.configuration.Configuration
import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.functions.co.RichCoFlatMapFunction
import org.apache.flink.streaming.api.scala._
import org.apache.flink.util.Collector

object AdvancedStatefulFlyingCarpetJob {
  // The source, at a rate of 10 elements/sec.
  val simpleTransactionSource = new ThrottlingSource[SimpleTransaction](new SimpleTransactionSource, 1)

  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime)

    val inputStream: DataStream[SimpleTransaction] = env.addSource(simpleTransactionSource)
    val result: DataStream[ScoringResult] = createJob(inputStream)

    result.print()

    println(env.getExecutionPlan)

    // execute program
    env.execute("Flink Advanced-keyed Fraudulent Transaction")
  }

  def createJob(inputStream: DataStream[SimpleTransaction]): DataStream[ScoringResult] = {
    // Give unique Id to incoming event for joining later in the chain.
    val uuidStream: DataStream[UuidTransaction] = inputStream.map { simpleTransaction =>
      println(s"simpleTransaction = $simpleTransaction")
      val numberOfKeys = Manager.definedKeys.size
      // This is converted to Map[String, Any] because 'we cannot know beforehand what types are coming in'.
      UuidTransaction(java.util.UUID.randomUUID, numberOfKeys, simpleTransaction.toMap)
    }

    // Determine which operations we need to perform on each 'node'.
    val customKeyStream: DataStream[DynamicKeyEvent] = uuidStream
        .flatMap[DynamicKeyEvent](
      (transaction: UuidTransaction, coll: Collector[DynamicKeyEvent]) =>
        Manager.definedKeys.foreach { key =>
          val featureToCalculate = Manager.featuresForKey(key)

          // extract only values needed for feature calculation from the payload
          val requiredPayload = featureToCalculate.requiredInput.map(fieldName => fieldName -> transaction.payload(fieldName)).toMap

          val keyValue = key.map(keyFieldName => keyFieldName -> transaction.payload(keyFieldName))
          coll.collect(
            // `key take-away` the key is a composition of keyname and value of that key.
            // By doing this we can ensure that the 'following' events will end up at the same node.
            DynamicKeyEvent(transaction.uuid,  featureToCalculate.featureName, keyValue, transaction.expectedNumberOfKeys, requiredPayload)
          )
        }
    )

    // Perform operation at the node where the key belongs.
    val stateStream: DataStream[ResultEvent] = customKeyStream
        .keyBy(_.artificialKey)
        .mapWithState[ResultEvent, Map[String, Value]] {
      case (event: DynamicKeyEvent, maybeState: Option[Map[String, Value]]) =>
        val featureToCalculate = Manager.featuresForKey(event.artificialKey.map(_._1))

        // assign the `program` we want to execute on the 'Value'.
        val operation: (String, Value) => StateF[Double] = featureToCalculate.operation

        // prepare input for the calculation
        import io.github.exploiting.flinks.stateful.operators.magic.ToTuple._
        val operationInputValue: Product = featureToCalculate.requiredInput.map(event.payload(_)).toTuple

        // Initialize the interpreter that will be executing our `program`
        val interpreter = FlinkInterpreter(maybeState)

        // Execute the program, return type for now is Double, but could be Any.
        val result: Double = operation(event.featureName, operationInputValue).foldMap(interpreter)

        // Return the result, and assign the new state to this operator.
        (ResultEvent(event.uuid, event.featureName, result, event.expectedNumberOfKeys), Some(interpreter.state))
    }

    // Join the original event with the picked up state based on UUID.
    val enrichedStream: DataStream[EnrichedTransaction] = uuidStream
        .keyBy(uuidTransaction => uuidTransaction.uuid)
        .connect(stateStream.keyBy(results => results.uuid))
        .flatMap(new JoinStreams)

    //now we can score the improved model
    val result = enrichedStream.map(event =>
      ScoringResult(event, FraudRules.scoreAdvancedFlyingCarpet(event))
    )

    result
  }
}

class JoinStreams extends RichCoFlatMapFunction[UuidTransaction, ResultEvent, EnrichedTransaction] {

  import scala.collection.JavaConverters._

  private var resultEvents: MapState[String, Any] = _
  private var originalEvent: ListState[UuidTransaction] = _

  private def resultEventsAsScalaMap: Map[String, Any] = Option(resultEvents.entries()).fold(Map.empty[String, Any])(_.iterator().asScala.toList.map(entry => entry.getKey -> entry.getValue).toMap)

  private def numberOfResultEvents: Int = resultEvents.keys().asScala.size
  private def enrichedEventsAsScalaIterable: Iterable[UuidTransaction] = originalEvent.get.asScala
  private def numberOfEnrichedEvents: Int = originalEvent.get.asScala.size

  override def open(config: Configuration): Unit = {
    super.open(config)
    val resultEventDesc: MapStateDescriptor[String, Any] = new MapStateDescriptor("resultEvents", classOf[String], classOf[Any])
    resultEvents = getRuntimeContext.getMapState(resultEventDesc)

    val uuidDesc: ListStateDescriptor[UuidTransaction] = new ListStateDescriptor("uuidDescriptor", classOf[UuidTransaction])
    originalEvent = getRuntimeContext.getListState(uuidDesc)
  }

  /**
    * What do we do, when an UUIDtransaction comes in?
    * First, check if there are already resultevents, (are we complete? => collect) otherwise update state and continue.
    */
  override def flatMap1(value: UuidTransaction, out: Collector[EnrichedTransaction]): Unit = {
    val expectedResults = value.expectedNumberOfKeys

    if (numberOfResultEvents == expectedResults) {
      // We're complete, collect.
      out.collect(EnrichedTransaction(value.uuid, value.payload, resultEventsAsScalaMap))
      resultEvents.clear()
      originalEvent.clear()
    }
    else {
      originalEvent.add(value)
    }
  }

  override def flatMap2(value: ResultEvent, out: Collector[EnrichedTransaction]): Unit = {

    if (numberOfEnrichedEvents > 0) {
      val expectedResults = value.expectedAmount

      if (numberOfResultEvents +1 == expectedResults) {
        val uuidTransactionFromState = enrichedEventsAsScalaIterable.head
        // append the new element to the results.
        out.collect(
          EnrichedTransaction(uuidTransactionFromState.uuid,
            uuidTransactionFromState.payload,
            resultEventsAsScalaMap + (value.featureName -> value.result))
        )

        resultEvents.clear()
        originalEvent.clear()
      }
      else {
        // we're not complete yet. update state.
        resultEvents.put(value.featureName, value.result)
      }
    }
    else {
      // we don't have the uuidevent yet.
      resultEvents.put(value.featureName, value.result)
    }
  }
}
