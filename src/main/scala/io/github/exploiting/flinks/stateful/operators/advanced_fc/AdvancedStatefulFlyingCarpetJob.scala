package io.github.exploiting.flinks.stateful.operators.advanced_fc

import io.github.exploiting.flinks.stateful.operators.magic.Mappable._
import io.github.exploiting.flinks.stateful.operators.model._
import io.github.exploiting.flinks.stateful.operators.{SimpleTransactionSource, ThrottlingSource}
import org.apache.flink.api.common.state._
import org.apache.flink.configuration.Configuration
import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.functions.co.RichCoFlatMapFunction
import org.apache.flink.streaming.api.scala._
import org.apache.flink.util.Collector

import scala.tools.nsc.interpreter

object AdvancedStatefulFlyingCarpetJob {
  // The source, at a rate of 10 elements/sec.
  val simpleTransactionSource = new ThrottlingSource[SimpleTransaction](new SimpleTransactionSource, 1)

  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime)

    val inputStream: DataStream[SimpleTransaction] = env.addSource(simpleTransactionSource)
    val result: DataStream[ScoringResult] = createJob(inputStream)

    result.print()

    println(env.getExecutionPlan)

    // execute program
    env.execute("Flink Advanced-keyed Fraudulent Transaction")
  }

  def createJob(inputStream: DataStream[SimpleTransaction]): DataStream[ScoringResult] = {
    // Give unique Id to incoming event for joining later in the chain.
    val uuidStream: DataStream[UuidTransaction] = inputStream.map { simpleTransaction =>
      println(s"simpleTransaction = $simpleTransaction")

      val numberOfKeys = Manager.definedKeys.size
      // This is converted to Map[String, Any] because 'we cannot know beforehand what types are coming in'.
      UuidTransaction(java.util.UUID.randomUUID, numberOfKeys, simpleTransaction.toMap)
    }

    // Determine which operations we need to perform on each 'node'.
    val customKeyStream: DataStream[DynamicKeyEvent] = uuidStream.flatMap[DynamicKeyEvent] {
      (transaction: UuidTransaction, coll: Collector[DynamicKeyEvent]) =>
        Manager.definedKeys.foreach { key =>
          val featureToCalculate = Manager.featureForKey(key)
          val requiredPayload = featureToCalculate.filterRequiredInput(transaction.payload)
          val keyValue = key.getValue(transaction.payload)

          coll.collect(
            // `key take-away` the key is a composition of keyname and value of that key.
            // By doing this we can ensure that the 'following' events will end up at the same node.
            DynamicKeyEvent(transaction.uuid, featureToCalculate.featureName, keyValue, transaction.expectedNumberOfKeys, requiredPayload)
          )
        }
    }

    // Perform operation at the node where the key belongs.
    val stateStream: DataStream[ResultEvent] = customKeyStream
        .keyBy(_.artificialKey)
        .mapWithState[ResultEvent, Map[String, Value]] {
      case (event: DynamicKeyEvent, maybeState: Option[Map[String, Value]]) =>
        val featureToCalculate = Manager.featureForKey(event.artificialKey.map(_._1))
        val (featureResult, newState) = featureToCalculate.calculate(maybeState, event)

        // Return the result, and assign the new state to this operator.
        (ResultEvent(event.uuid, event.featureName, featureResult, event.expectedNumberOfKeys), Some(newState))
    }

    // Join the original event with the picked up state based on UUID.
    val enrichedStream: DataStream[EnrichedTransaction] = uuidStream
        .keyBy(uuidTransaction => uuidTransaction.uuid)
        .connect(stateStream.keyBy(results => results.uuid))
        .flatMap(new JoinStreams)

    //now we can score the improved model
    val result = enrichedStream.map(event =>
      ScoringResult(event, FraudRules.scoreAdvancedFlyingCarpet(event))
    )

    result
  }

}

class JoinStreams extends RichCoFlatMapFunction[UuidTransaction, ResultEvent, EnrichedTransaction] {

  import scala.collection.JavaConverters._

  private var resultEvents: MapState[String, Any] = _
  private var originalEvent: ValueState[UuidTransaction] = _

  private def resultEventsAsScalaMap: Map[String, Any] = Option(resultEvents.entries()).fold(Map.empty[String, Any])(_.iterator().asScala.toList.map(entry => entry.getKey -> entry.getValue).toMap)

  private def numberOfResultEvents: Int = resultEvents.keys().asScala.size

  private def getOriginalEvent: UuidTransaction = Option(originalEvent.value()).get

  private def originalEventAlreadyArrived: Boolean = Option(originalEvent.value()).isDefined

  override def open(config: Configuration): Unit = {
    super.open(config)
    val resultEventDesc: MapStateDescriptor[String, Any] = new MapStateDescriptor("resultEvents", classOf[String], classOf[Any])
    resultEvents = getRuntimeContext.getMapState(resultEventDesc)

    val uuidDesc: ValueStateDescriptor[UuidTransaction] = new ValueStateDescriptor("uuidDescriptor", classOf[UuidTransaction])
    originalEvent = getRuntimeContext.getState(uuidDesc)
  }

  /**
    * What do we do, when an UUIDtransaction comes in?
    * First, check if there are already resultevents, (are we complete? => collect) otherwise update state and continue.
    */
  override def flatMap1(value: UuidTransaction, out: Collector[EnrichedTransaction]): Unit = {
    val expectedResults = value.expectedNumberOfKeys

    if (numberOfResultEvents == expectedResults) {
      // We're complete, collect.
      out.collect(EnrichedTransaction(value.uuid, value.payload, resultEventsAsScalaMap))

      resultEvents.clear()
      originalEvent.clear()
    }
    else {
      originalEvent.update(value)
    }
  }

  override def flatMap2(value: ResultEvent, out: Collector[EnrichedTransaction]): Unit = {

    if (originalEventAlreadyArrived && (numberOfResultEvents + 1 == value.expectedNumberOfKeys)) {
      // We're complete, collect.
      val originalEventFromState = getOriginalEvent
      out.collect(
        EnrichedTransaction(
          originalEventFromState.uuid,
          originalEventFromState.payload,
          resultEventsAsScalaMap + (value.featureName -> value.result)) // append the new element to the results.
      )

      resultEvents.clear()
      originalEvent.clear()
    }
    else {
      // we're not complete yet. update state.
      resultEvents.put(value.featureName, value.result)
    }
  }
}
